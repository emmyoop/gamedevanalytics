{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def load_data():\n",
    "    def try_literal_eval(s):\n",
    "        try:\n",
    "            return literal_eval(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "\n",
    "\n",
    "    steam_data = pd.read_csv('initial_preprocessed.csv') \n",
    "    # steam_data = pd.json_normalize(steam_data, errors='ignore')\n",
    "    # all columns that are dicts are being read in as strings - look in to json_normalize as possibly better solution?\n",
    "    steam_data['price_overview'] = steam_data.price_overview.apply(try_literal_eval)\n",
    "    steam_data['platforms'] = steam_data.platforms.apply(try_literal_eval)\n",
    "    steam_data['recommendations'] = steam_data.recommendations.apply(try_literal_eval)\n",
    "    steam_data['screenshots'] = steam_data.screenshots.apply(try_literal_eval)\n",
    "    steam_data['movies'] = steam_data.movies.apply(try_literal_eval)\n",
    "    steam_data['genres'] = steam_data.genres.apply(try_literal_eval)\n",
    "    steam_data['release_date'] = steam_data.release_date.apply(try_literal_eval)\n",
    "    steam_data['fullgame'] = steam_data.fullgame.apply(try_literal_eval)\n",
    "    steam_data['demos'] = steam_data.demos.apply(try_literal_eval)\n",
    "    steam_data['categories'] = steam_data.categories.apply(try_literal_eval)\n",
    "    steam_data['metacritic'] = steam_data.metacritic.apply(try_literal_eval)\n",
    "    steam_data['achievements'] = steam_data.achievements.apply(try_literal_eval)\n",
    "\n",
    "    return steam_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_field(df, field, rename_dict, drops_list):\n",
    "    '''\n",
    "    takes in a dataframe column that is a dict and seprates it into \n",
    "    separate columns per key/value pair.  Can rename cols and drop \n",
    "    columns as specified\n",
    "    \n",
    "    df: dataframe to alter\n",
    "    field: column to flatten\n",
    "    rename_dict: dictionary of current_name: new_name pairs for updating\n",
    "    drops_list: list of new columns to drop\n",
    "    '''\n",
    "    df_clean = pd.concat([df, df[field].apply(pd.Series)], axis=1)\n",
    "    df_clean.drop(axis=1, columns=drops_list, inplace=True)\n",
    "    df_clean.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def convert_to_datetime(df, col, rename_dict, drops_list):\n",
    "    '''\n",
    "    Takes in a dataframe column that is a dict.  Pulls the \n",
    "    dict into columns and takes the date column into a dattime \n",
    "    object.  Assumes a date format pandas can distinguish.\n",
    "    '''\n",
    "    s = df[col].apply(pd.Series)\n",
    "    s['date'] = pd.to_datetime(s['date'], errors='coerce')\n",
    "\n",
    "    df_clean = pd.concat([df, s], axis=1)\n",
    "    df_clean.drop(axis=1, columns=drops_list, inplace=True)\n",
    "    df_clean.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def remove_unused_data(df, column, valid_list):\n",
    "    '''\n",
    "    Removes rows that so not match any values in the valid_list \n",
    "    for the column\n",
    "    '''\n",
    "\n",
    "    contains = [df['type'].str.contains(i) for i in valid_list]\n",
    "    df_clean = df[np.any(contains, axis=0)]\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def map_to_bool(df, mapping, col):\n",
    "    '''\n",
    "    maps values in a column to be just bools\n",
    "    df: dataframe\n",
    "    mapping: dict of mappings ex: {np.nan: False, 'full': True}\n",
    "    col: name of col to convert\n",
    "    '''\n",
    "    return df[col].map(mapping)\n",
    "\n",
    "def replace_with_count(df, col):\n",
    "    '''\n",
    "    gets the length of a column that is of type list\n",
    "    '''\n",
    "    df = pd.concat([df, df[col].str.len()], axis=1)\n",
    "    # this results in both old and new columns having the same name \n",
    "    # so below code will remove the old screenshots dictionary column\n",
    "    df = df.loc[:,~df.columns.duplicated(keep='last')]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_unique_bool_cols(df, col, prefix):\n",
    "    '''\n",
    "    Takes in a single columns in a dataframe, detmerines all unique values, \n",
    "    creates a column for each unique value in the dataframe and fills it \n",
    "    with a bool for each row indicating if that values exists for that row\n",
    "    \n",
    "    assumes column splits out into ['id','description'] pairs for uniqueness\n",
    "    \n",
    "    new column names will all be delimited with underscore\n",
    "    \n",
    "    df: Dataframe\n",
    "    col: column to split out into multiple bool columns\n",
    "    prefix: prefix of the new column names (genre -> genre_action, genre_adventure...).  \n",
    "    Will use description to build new column name\n",
    "    '''\n",
    "    # first we need to create a table of all possible values then store those so we can access them\n",
    "    s = df[col].apply(pd.Series)\n",
    "    # combine everything into single column\n",
    "    #todo: add logic to know number of cols on the fly\n",
    "    y = s[0].append([s[1],s[2],s[3],s[4],s[5],s[6],s[7],s[8],s[9]],ignore_index=True).dropna()\n",
    "    #split out dict to seprate columns\n",
    "    z = y.apply(pd.Series)\n",
    "    z = z.drop_duplicates(subset=['id','description'], keep=\"first\")\n",
    "\n",
    "    # create a new column for each unique value\n",
    "    for index, row in z.iterrows():\n",
    "        new_col = '{0} {1}'.format(prefix, row['description']).replace(\" \", \"_\")\n",
    "        df[new_col] = False\n",
    "\n",
    "    # then fill those columns in the Dataframe with bools\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row[col]) == float:\n",
    "            continue\n",
    "        for item in row[col]:\n",
    "            new_name = '{0} {1}'.format(prefix, item['description']).replace(\" \", \"_\")\n",
    "    # because you can't update on  iterrows()\n",
    "            df.at[index, new_name] = True\n",
    "    \n",
    "    # drop the original column at the edn of processing\n",
    "    df.drop(axis=1, columns=col, inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions specific to my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cleanup(df):\n",
    "    \n",
    "    del_cols = ['index',\n",
    "        'success',\n",
    "        'header_image',\n",
    "        'pc_requirements',\n",
    "        'mac_requirements',\n",
    "        'linux_requirements',\n",
    "        'support_info',\n",
    "        'background',\n",
    "        'legal_notice',\n",
    "        'reviews',\n",
    "        'content_descriptors']\n",
    "\n",
    "    num_type_list = ['required_age']\n",
    "    \n",
    "    rename_dict = {\n",
    "        'name': 'game_name'\n",
    "    }\n",
    "    \n",
    "    # set steam_appid as index\n",
    "    df.set_index('steam_appid')\n",
    "\n",
    "    # remove columns we don't care about\n",
    "    df_clean = df.drop(columns=del_cols, axis=1)\n",
    "    \n",
    "    # rename columns as appropriate\n",
    "    df_clean.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    \n",
    "    #update types to numeric\n",
    "    for i in num_type_list:\n",
    "        df_clean[i] = pd.to_numeric(df_clean[i])\n",
    "    \n",
    "    # update types to datetime\n",
    "    df_clean = convert_to_datetime(df_clean, 'release_date', {'date': 'release_date'}, ['release_date'])\n",
    "    \n",
    "    # trim down to just below types\n",
    "    valid_types = ['game', 'dlc', 'demo']\n",
    "    df_clean = remove_unused_data(df_clean, 'type', valid_types)\n",
    "\n",
    "    # flatten cols as possible\n",
    "    df_clean = flatten_price(df_clean)\n",
    "    df_clean = flatten_platform(df_clean)\n",
    "    df_clean = flatten_field(df_clean, \n",
    "                             'recommendations', \n",
    "                             {'total': 'recommendations'}, \n",
    "                             [0, 'recommendations'])\n",
    "    df_clean = flatten_field(df_clean, \n",
    "                             'metacritic', \n",
    "                             {'score': 'metacritic_score'}, \n",
    "                             ['metacritic', 0, 'url'])\n",
    "    df_clean = flatten_field(df_clean, \n",
    "                             'fullgame', \n",
    "                             {'appid': 'fullgame_appid'}, \n",
    "                             ['fullgame', 'name', 0])\n",
    "    df_clean = flatten_field(df_clean, \n",
    "                             'achievements', \n",
    "                             {\"total\": \"achievement_count\"}, \n",
    "                             [0, 'achievements', 'highlighted'])\n",
    "    \n",
    "    \n",
    "    # there seems to be only 1 demo in the subset i pulled so we'll just show that one demo id instead of the dict\n",
    "    s = df_clean['demos'].apply(pd.Series)\n",
    "    s['demo_appid'] = s[0].apply(lambda x: str(x['appid']) if not pd.isnull(x) else np.nan)\n",
    "    df_clean = pd.concat([df_clean, s['demo_appid']], axis=1)\n",
    "    # drop the original column at the edn of processing\n",
    "    df_clean.drop(axis=1, columns='demos', inplace=True)\n",
    "    \n",
    "    \n",
    "    # convert cols to bool type\n",
    "    bool_col = 'controller_support'\n",
    "    controller_mapping = {np.nan: False, 'full': True}\n",
    "    df_clean[bool_col] = map_to_bool(df_clean, controller_mapping, bool_col)\n",
    "    \n",
    "    # convert cols to just counts\n",
    "    df_clean = replace_with_count(df_clean, 'screenshots')\n",
    "    df_clean.rename(columns={'screenshots': 'screenshot_count'}, inplace=True)\n",
    "\n",
    "    df_clean = replace_with_count(df_clean, 'movies')\n",
    "    df_clean.rename(columns={'movies': 'movie_count'}, inplace=True)\n",
    "    \n",
    "    df_clean = replace_with_count(df_clean, 'dlc')\n",
    "    df_clean.rename(columns={'dlc': 'dlc_count'}, inplace=True)\n",
    "    \n",
    "    # convert lists to bools for easy categorization\n",
    "    df_clean = create_unique_bool_cols(df_clean, 'genres', 'genre')\n",
    "    df_clean = create_unique_bool_cols(df_clean, 'categories', 'category')\n",
    "\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def flatten_price(df):\n",
    "    field_to_rename = {'currency': 'price_currency',\n",
    "                         'discount_percent': 'price_discount_percent', \n",
    "                         'final': 'price_final', \n",
    "                         'initial': 'price_initial',\n",
    "                         'recurring_sub': 'price_recurring_sub',\n",
    "                         'recurring_sub_desc': 'price_recurring_sub_desc'}\n",
    "    fields_to_drop = ['price_overview', 0, 'final_formatted', 'initial_formatted']\n",
    "    \n",
    "    df_clean = flatten_field(df, 'price_overview', field_to_rename, fields_to_drop)\n",
    "        \n",
    "    df_clean['price_final'] = df_clean['price_final'] / 100\n",
    "    df_clean['price_initial'] = df_clean['price_initial'] / 100\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def flatten_platform(df):\n",
    "    fields_to_rename = {'windows': 'windows_support', \n",
    "                       'mac': 'mac_support', \n",
    "                       'linux': 'linux_support'}\n",
    "    fields_to_drop = ['platforms']\n",
    "    \n",
    "    df_clean = flatten_field(df, 'platforms', fields_to_rename, fields_to_drop)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually run the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steam_data = load_data()\n",
    "\n",
    "data1 = initial_cleanup(steam_data)\n",
    "\n",
    "\n",
    "data1.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0c03bd9c4e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# engine.execute(\"SELECT * FROM test\").fetchall()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 999)\n",
    "# data1['achievement_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to csv to compare results\n",
    "data1.to_csv('consolidated_processed.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 2)\n",
      "(37, 3)\n",
      "   id description   0\n",
      "0 NaN         NaN NaN\n"
     ]
    }
   ],
   "source": [
    "def create_unique_bool_cols(df, col, prefix):\n",
    "\n",
    "    s = df[col].apply(pd.Series)\n",
    "    size = s.shape\n",
    "    y = s[0].append([s[1],s[2],s[3],s[4],s[5],s[6],s[7],s[8],s[9]],ignore_index=True).dropna()\n",
    "\n",
    "    #split out dict to seprate columns\n",
    "    z = y.apply(pd.Series)\n",
    "    z = z.drop_duplicates(subset=['id','description'], keep=\"first\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    s2 = df[col].apply(pd.Series)\n",
    "    size2 = s2.shape[1]\n",
    "#     s2.apply(lambda x: x.str.cat(sep=','), axis=1)\n",
    "    some_list = s2[0].tolist()\n",
    "    for x in range(1,size2):\n",
    "        l = s2[x].dropna().tolist()\n",
    "        some_list += l\n",
    "\n",
    "    y2 = pd.Series(some_list)\n",
    "    \n",
    "#     y2 = y2.dropna()\n",
    "    \n",
    "    z2 = y2.apply(pd.Series)\n",
    "    z2 = z2.drop_duplicates(subset=['id','description'], keep=\"first\")\n",
    "#     new = pd.DataFrame([z2['description']])\n",
    "#     print(new.shape)\n",
    "    \n",
    "    print(z.shape)\n",
    "    print(z2.shape)\n",
    "    compare = pd.concat([z,z2]).drop_duplicates(keep=False)\n",
    "    print(compare)\n",
    "\n",
    "#     # create a new column for each unique value\n",
    "#     for index, row in z.iterrows():\n",
    "#         new_col = '{0} {1}'.format(prefix, row['description']).replace(\" \", \"_\")\n",
    "#         df[new_col] = False\n",
    "\n",
    "#     # then fill those columns in the Dataframe with bools\n",
    "#     for index, row in df.iterrows():\n",
    "#         if type(row[col]) == float:\n",
    "#             continue\n",
    "#         for item in row[col]:\n",
    "#             new_name = '{0} {1}'.format(prefix, item['description']).replace(\" \", \"_\")\n",
    "#     # because you can't update on  iterrows()\n",
    "#             df.at[index, new_name] = True\n",
    "    \n",
    "#     # drop the original column at the edn of processing\n",
    "#     df.drop(axis=1, columns=col, inplace=True)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "steam_data = load_data()\n",
    "df_test = create_unique_bool_cols(steam_data, 'categories', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'tostr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-cdcb606610ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msteam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'publishers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'tostr'"
     ]
    }
   ],
   "source": [
    "steam_data['publishers'].tostr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
